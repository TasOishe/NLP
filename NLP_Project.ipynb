{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNSoceEQifQmCj32wbB9xgK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TasOishe/NLP/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of BERT and SciBERT for Relation Classification and Named Entity Recognition\n",
        "\n"
      ],
      "metadata": {
        "id": "DXmWTLtnNQJi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXZvRfJPIDSK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets seqeval evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
        ")\n",
        "from datasets import load_dataset, Dataset\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "V8ezoQOuIOJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scierc = load_dataset(\"nsusemiehl/SciERC\")\n",
        "\n",
        "\n",
        "scierc_train_sample = scierc[\"train\"].select(range(100))\n",
        "scierc_dev_sample   = scierc[\"validation\"].select(range(100))\n",
        "scierc_test_sample  = scierc[\"test\"].select(range(100))\n",
        "\n",
        "\n",
        "from datasets import DatasetDict\n",
        "\n",
        "scierc_small = DatasetDict({\n",
        "    \"train\": scierc_train_sample,\n",
        "    \"validation\": scierc_dev_sample,\n",
        "    \"test\": scierc_test_sample\n",
        "})\n",
        "\n",
        "\n",
        "print(scierc_small)\n",
        "print(scierc_small[\"train\"][0])\n",
        "print(scierc_small[\"validation\"][0])\n",
        "print(scierc_small[\"test\"][0])\n"
      ],
      "metadata": {
        "id": "SFdrfymcISq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "bc5cdr_path = Path(\"/content/drive/MyDrive/BC5CDR\")\n",
        "\n",
        "\n",
        "train_file = bc5cdr_path / \"train.json\"\n",
        "test_file  = bc5cdr_path / \"test.json\"\n",
        "\n",
        "with open(train_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "\n",
        "with open(test_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "\n",
        "print(\"Number of training samples:\", len(train_data))\n",
        "print(\"Number of test samples:\", len(test_data))\n",
        "print(\"First training sample:\", train_data[0])"
      ],
      "metadata": {
        "id": "cf3QuKiUIV57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "\n",
        "bc5cdr_dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_list(train_data),\n",
        "    \"test\": Dataset.from_list(test_data)\n",
        "})\n",
        "\n",
        "\n",
        "bc5cdr_dataset[\"train\"] = bc5cdr_dataset[\"train\"].select(range(100))\n",
        "bc5cdr_dataset[\"test\"] = bc5cdr_dataset[\"test\"].select(range(100))\n",
        "\n",
        "\n",
        "print(bc5cdr_dataset[\"train\"][0])"
      ],
      "metadata": {
        "id": "DcfD2CBtIY8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bc5_tags_to_bio(example):\n",
        "    bio_labels = []\n",
        "    for t in example[\"tags\"]:\n",
        "        if t == 0:\n",
        "            bio_labels.append(\"O\")\n",
        "        else:\n",
        "            bio_labels.append(\"B-Chemical\")\n",
        "    return {\"tokens\": example[\"tokens\"], \"ner_tags\": bio_labels}\n",
        "\n",
        "\n",
        "bc5cdr_dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_list([bc5_tags_to_bio(x) for x in train_data[:100]]),\n",
        "    \"test\": Dataset.from_list([bc5_tags_to_bio(x) for x in test_data[:100]])\n",
        "})\n",
        "\n",
        "\n",
        "print(bc5cdr_dataset[\"train\"][0])\n",
        "print(bc5cdr_dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "iQWMhcDIIbAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_list(dataset, label_column):\n",
        "    unique_labels = set()\n",
        "    for example in dataset[\"train\"][label_column]:\n",
        "        if isinstance(example, list):\n",
        "            unique_labels.update(example)\n",
        "        else:\n",
        "            unique_labels.add(example)\n",
        "    return sorted(list(unique_labels))\n",
        "\n",
        "\n",
        "scierc_labels = get_label_list(scierc_small, \"label\")\n",
        "\n",
        "\n",
        "bc5_labels = get_label_list(bc5cdr_dataset, \"ner_tags\")\n",
        "\n",
        "print(\"SciERC labels:\", scierc_labels)\n",
        "print(\"BC5 labels:\", bc5_labels)\n"
      ],
      "metadata": {
        "id": "ChQldtb8IdTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SciERC columns:\", scierc_small[\"train\"].column_names)\n",
        "print(\"First train example:\", scierc_small[\"train\"][0])\n"
      ],
      "metadata": {
        "id": "DSJah199Ih9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_label_list_from_column(dataset, column):\n",
        "    return sorted(set(dataset[\"train\"][column]))\n",
        "\n",
        "scierc_rel_labels = build_label_list_from_column(scierc_small, \"label\")\n",
        "print(\"SciERC relation labels:\", scierc_rel_labels)\n",
        "\n",
        "\n",
        "label2id_scierc = {l: i for i, l in enumerate(scierc_rel_labels)}\n",
        "id2label_scierc = {i: l for l, i in label2id_scierc.items()}\n",
        "\n",
        "\n",
        "def map_scierc_label_to_id(example):\n",
        "    lab_val = example[\"label\"]\n",
        "    example[\"label_id\"] = label2id_scierc[lab_val]\n",
        "    return example\n",
        "\n",
        "scierc_small = scierc_small.map(map_scierc_label_to_id)\n",
        "print(\"Example after mapping:\", scierc_small[\"train\"][0])\n"
      ],
      "metadata": {
        "id": "sGfCN8jxIkx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_scierc(examples, tokenizer):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels_bc5(examples, tokenizer, label2id):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label2id[label[word_idx]])\n",
        "            else:\n",
        "\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "26cDdVZAIow6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "tokenized_scierc = scierc_small.map(\n",
        "    lambda x: tokenize_scierc(x, tokenizer),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "print(\"Tokenized SciERC example:\", tokenized_scierc[\"train\"][0])\n",
        "\n",
        "\n",
        "bc5_labels = [\"O\", \"B-Chemical\"]\n",
        "label2id_bc5 = {l: i for i, l in enumerate(bc5_labels)}\n",
        "id2label_bc5 = {i: l for l, i in label2id_bc5.items()}\n",
        "\n",
        "tokenized_bc5 = bc5cdr_dataset.map(\n",
        "    lambda x: tokenize_and_align_labels_bc5(x, tokenizer, label2id_bc5),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "print(\"Tokenized BC5CDR example:\", tokenized_bc5[\"train\"][0])\n"
      ],
      "metadata": {
        "id": "45GXRrZFIroZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
        "\n",
        "\n",
        "model_scierc = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=len(scierc_rel_labels),\n",
        "    id2label=id2label_scierc,\n",
        "    label2id=label2id_scierc\n",
        ")\n",
        "\n",
        "\n",
        "model_bc5 = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=len(bc5_labels),\n",
        "    id2label=id2label_bc5,\n",
        "    label2id=label2id_bc5\n",
        ")\n",
        "\n",
        "print(\"Models initialized successfully!\")\n"
      ],
      "metadata": {
        "id": "cuh01lZSIuLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "data_collator_bc5 = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "data_collator_scierc = None\n",
        "\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "seqeval_metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "\n",
        "def compute_metrics_scierc(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return accuracy_metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "\n",
        "def compute_metrics_bc5(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=2)\n",
        "    true_labels = [[id2label_bc5[l] for l in label if l != -100] for label in labels]\n",
        "    true_preds = [[id2label_bc5[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "                  for pred, label in zip(preds, labels)]\n",
        "    return seqeval_metric.compute(predictions=true_preds, references=true_labels)\n"
      ],
      "metadata": {
        "id": "2R1JD1xnIxCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "\n",
        "training_args_scierc = TrainingArguments(\n",
        "    output_dir=\"scierc-rel-bert\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir=\"./logs_scierc\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_strategy=\"steps\"\n",
        ")\n",
        "\n",
        "\n",
        "training_args_bc5 = TrainingArguments(\n",
        "    output_dir=\"bc5-ner-bert\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir=\"./logs_bc5\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_strategy=\"steps\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "LnQETh3uIzei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "\n",
        "trainer_scierc = Trainer(\n",
        "    model=model_scierc,\n",
        "    args=training_args_scierc,\n",
        "    train_dataset=tokenized_scierc[\"train\"],\n",
        "    eval_dataset=tokenized_scierc[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics_scierc\n",
        ")\n",
        "\n",
        "\n",
        "trainer_bc5 = Trainer(\n",
        "    model=model_bc5,\n",
        "    args=training_args_bc5,\n",
        "    train_dataset=tokenized_bc5[\"train\"],\n",
        "    eval_dataset=tokenized_bc5[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator_bc5,\n",
        "    compute_metrics=compute_metrics_bc5\n",
        ")\n",
        "\n",
        "print(\"Trainers initialized successfully!\")\n"
      ],
      "metadata": {
        "id": "hiVJY6HwI2RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "def tokenize_text(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "tokenized_scierc = scierc_small.map(tokenize_text, batched=True)\n",
        "\n",
        "\n",
        "def map_labels_to_int(example):\n",
        "    example[\"labels\"] = label2id_scierc.get(example[\"label\"], 0)\n",
        "    return example\n",
        "\n",
        "tokenized_scierc = tokenized_scierc.map(map_labels_to_int)\n",
        "\n",
        "\n",
        "columns_to_remove = [\"text\", \"label\", \"metadata\", \"label_id\"]\n",
        "for split in tokenized_scierc.keys():\n",
        "    tokenized_scierc[split] = tokenized_scierc[split].remove_columns(\n",
        "        [c for c in columns_to_remove if c in tokenized_scierc[split].column_names]\n",
        "    )\n",
        "\n",
        "\n",
        "model_scierc = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=len(scierc_labels)\n",
        ")\n",
        "\n",
        "\n",
        "training_args_scierc = TrainingArguments(\n",
        "    output_dir=\"scierc-rel-bert\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"scierc-logs\",\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "\n",
        "def compute_metrics_scierc(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    precision = precision_score(labels, preds, average=\"weighted\")\n",
        "    recall = recall_score(labels, preds, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }\n",
        "\n",
        "\n",
        "trainer_scierc = Trainer(\n",
        "    model=model_scierc,\n",
        "    args=training_args_scierc,\n",
        "    train_dataset=tokenized_scierc[\"train\"],\n",
        "    eval_dataset=tokenized_scierc[\"validation\"],\n",
        "    compute_metrics=compute_metrics_scierc\n",
        ")\n",
        "\n",
        "\n",
        "trainer_scierc.train()\n",
        "results_scierc = trainer_scierc.evaluate()\n",
        "print(\"SciERC Relation Classification Results(BERT):\", results_scierc)\n"
      ],
      "metadata": {
        "id": "mC46U5pwI4qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model_scibert = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"allenai/scibert_scivocab_uncased\",\n",
        "    num_labels=len(scierc_labels)\n",
        ")\n",
        "tokenizer_scibert = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "\n",
        "def tokenize_scierc(example):\n",
        "    return tokenizer_scibert(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_scierc = scierc_small.map(tokenize_scierc, batched=True)\n",
        "\n",
        "\n",
        "tokenized_scierc = tokenized_scierc.rename_column(\"label_id\", \"labels\")\n",
        "\n",
        "tokenized_scierc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
        "    prec = precision_score(labels, predictions, average=\"weighted\", zero_division=0)\n",
        "    rec = recall_score(labels, predictions, average=\"weighted\", zero_division=0)\n",
        "    return {\n",
        "        \"eval_accuracy\": acc,\n",
        "        \"eval_f1\": f1,\n",
        "        \"eval_precision\": prec,\n",
        "        \"eval_recall\": rec\n",
        "    }\n",
        "\n",
        "\n",
        "training_args_scibert = TrainingArguments(\n",
        "    output_dir=\"scierc-rel-scibert\",\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer_scibert = Trainer(\n",
        "    model=model_scibert,\n",
        "    args=training_args_scibert,\n",
        "    train_dataset=tokenized_scierc[\"train\"],\n",
        "    eval_dataset=tokenized_scierc[\"validation\"],\n",
        "    tokenizer=tokenizer_scibert,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer_scibert.train()\n",
        "metrics_scibert = trainer_scibert.evaluate(tokenized_scierc[\"test\"])\n",
        "print(\"SciERC Relation Classification Results (SciBERT):\", metrics_scibert)\n"
      ],
      "metadata": {
        "id": "lOD24srCI7BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "tokenizer_bert_bc5 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model_bert_bc5 = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=len(set(label for ex in bc5cdr_dataset[\"train\"][\"ner_tags\"] for label in ex))\n",
        ")\n",
        "\n",
        "\n",
        "all_bc5_labels = sorted(list(set(label for ex in bc5cdr_dataset[\"train\"][\"ner_tags\"] for label in ex)))\n",
        "label2id_bc5 = {l: i for i, l in enumerate(all_bc5_labels)}\n",
        "id2label_bc5 = {i: l for l, i in label2id_bc5.items()}\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer_bert_bc5(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label2id_bc5[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "tokenized_bc5 = bc5cdr_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer_bert_bc5)\n",
        "\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    true_labels = [[id2label_bc5[l] for l in label if l != -100] for label in labels]\n",
        "    true_preds  = [[id2label_bc5[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "                   for pred, label in zip(predictions, labels)]\n",
        "    results = seqeval.compute(predictions=true_preds, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"]\n",
        "    }\n",
        "\n",
        "\n",
        "training_args_bc5 = TrainingArguments(\n",
        "    output_dir=\"bc5-bert\",\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"bc5-logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer_bc5_bert = Trainer(\n",
        "    model=model_bert_bc5,\n",
        "    args=training_args_bc5,\n",
        "    train_dataset=tokenized_bc5[\"train\"],\n",
        "    eval_dataset=tokenized_bc5[\"test\"],\n",
        "    tokenizer=tokenizer_bert_bc5,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "trainer_bc5_bert.train()\n",
        "bc5_bert_results = trainer_bc5_bert.evaluate(tokenized_bc5[\"test\"])\n",
        "print(\"BC5CDR NER Results (BERT):\", bc5_bert_results)\n"
      ],
      "metadata": {
        "id": "iBx4AxnXI9-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer_scibert_bc5 = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model_scibert_bc5 = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"allenai/scibert_scivocab_uncased\",\n",
        "    num_labels=len(all_bc5_labels)\n",
        ")\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels_scibert(examples):\n",
        "    tokenized_inputs = tokenizer_scibert_bc5(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label2id_bc5[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_bc5_scibert = bc5cdr_dataset.map(tokenize_and_align_labels_scibert, batched=True)\n",
        "\n",
        "\n",
        "data_collator_scibert = DataCollatorForTokenClassification(tokenizer_scibert_bc5)\n",
        "\n",
        "\n",
        "training_args_bc5_scibert = TrainingArguments(\n",
        "    output_dir=\"bc5-scibert\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"bc5-scibert-logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer_bc5_scibert = Trainer(\n",
        "    model=model_scibert_bc5,\n",
        "    args=training_args_bc5_scibert,\n",
        "    train_dataset=tokenized_bc5_scibert[\"train\"],\n",
        "    eval_dataset=tokenized_bc5_scibert[\"test\"],\n",
        "    tokenizer=tokenizer_scibert_bc5,\n",
        "    data_collator=data_collator_scibert,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer_bc5_scibert.train()\n",
        "bc5_scibert_results = trainer_bc5_scibert.evaluate(tokenized_bc5_scibert[\"test\"])\n",
        "print(\"BC5CDR NER Results (SciBERT):\", bc5_scibert_results)\n"
      ],
      "metadata": {
        "id": "bIQGJwYGJAac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-llDv4syJCoe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}